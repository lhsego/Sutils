% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/logScore.R
\name{logScore}
\alias{logScore}
\title{Calculates log scores for a given matrix of predicted class
probabilities.}
\usage{
logScore(signatures, scale = TRUE)
}
\arguments{
\item{signatures}{data.frame containing the true classes and class prediction
probabilities for each signature. See details.}

\item{scale}{a boolean value: Should the scores be scaled so 1 is the 
maximum and 0 corresponds to uniform predictions.}
}
\value{
a data.frame containing signature IDs, log scores,
and information scores
}
\description{
For a data.frame of signatures, class prediction probabilities and true 
classes, this function computes the logarithmic score
for each signature and returns a data frame containing the results.
}
\details{
The data.frame \code{signatures} has the following columns: signatureID, 
truthClass, and multiple columns beginning with 'predictionClass' followed by
the class name. Each signature (denoted by 'signatureID') consists of many
observations, each of which has a true class membership (denoted by
'truthClass') and a corresponding probability value for membership in each 
class (denoted by 'predictionClass'+className). The rows of \code{signatures} 
correspond to each observation for which a classification is made.

Let \eqn{p_k, k = 1,\ldots,n}{p_k, k=1,...,n} indicate the class predictions
where each \eqn{p_k}{p_k} corresponds to a single line in the \code{signatures}
data.frame and \eqn{n = nrow(signatures)}.  Let \eqn{J} denote the number of
classes. Let \eqn{\delta_{jk} = 1}{\delta_jk = 1} if 
and only if element \eqn{k} truly belongs to class \eqn{j}, 0 otherwise. Then
the log score is defined to be 
\deqn{L = \frac{1}{n}\sum_{k=1}^n\sum_{j=1}^J \delta_{jk}log(p_jk)}{L = (1/n)\sum_k \sum_j (\delta_jk)log(p_jk)}
The log score has a range of \eqn{(-\infty,0]} where larger scores are
better.

Strictly proper scoring rules can be decomposed into the sum of two 
components, one of which measures the sharpness of probability assignments
(i.e. the degree to which the probability assignment is placed on a single
or very few classes) and the other which is a measure of calibration or 
accuracy (i.e. the degree to which the probability assignments match the true
class).

In the decomposition of the log score, the measure of sharpness is given by
the negative entropy, or information, of the probabilities.
\deqn{I = -\frac{1}{n}\sum_{k=1}^n\sum_{j=1}^J(p_jk)log(p_jk)}{I = -(1/n)\sum_k \sum_j (p_jk)log(p_jk)}
The log score and information are returned by this function.

To facilitate side-by-side comparison with the Brier score (see
\code{\link{brierScore}}) we can transform the log score so that the maximum
value is 1 and a uniform probability assignment
gives a score of 0. The unscaled log score for uniform probability 
assignments is \eqn{L = -log(J)}. Then the scaled log score is given by 
\deqn{L^R = 1+1/log(J)*L}
The scaled log score takes values in \eqn{(-\infty, 1]}.
Likewise, the information scores are scaled in the same manner. 
If \code{scale=TRUE} the scaled log score and scaled 
information are returned.
}

